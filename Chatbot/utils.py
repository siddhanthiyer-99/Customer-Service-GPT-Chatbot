import os
import re
import logging
from time import time
import streamlit as st
from datetime import datetime
from tiktoken import get_encoding
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from simple_salesforce import Salesforce
from pymongo.collection import Collection
from langchain_core.prompts import PromptTemplate
from langchain_community.callbacks import get_openai_callback
from langchain_community.vectorstores.mongodb_atlas import MongoDBAtlasVectorSearch


def calculate_tokens(string: str) -> int:
    """
    Calculates the number of tokens in the provided string using the 'cl100k_base' encoding.

    Parameters:
        string (str): The input string for which tokens need to be calculated.

    Returns:
        int: The number of tokens in the input string after encoding.

    Example:
        >>> calculate_tokens("This is a sample string.")
        5
    """
    encoding = get_encoding('cl100k_base')
    num_tokens = len(encoding.encode(string))
    return num_tokens

def classify_query(llm: ChatOpenAI, query: str, classification_template: PromptTemplate) -> list[str]:
    """
    Classifies a query using the provided ChatOpenAI language model.

    Parameters:
        llm (ChatOpenAI): The ChatOpenAI language model instance to use for classification.
        query (str): The query to be classified.
        classification_template (str): The classification template used for invoking the language model.

    Returns:
        list[str]: A list of labels assigned to the query by the language model.

    Example:
        >>> classify_query(llm_instance, "Tell me about product A")
        ['query', 'product_query']
    """
    label = llm.invoke(classification_template.format(query=query)).content
    return label.replace('\n','').replace(' ','').replace("'",'').replace("*","").split('-')

def query_rewiriter(llm: ChatOpenAI, memory: str, query_rewriter_template: PromptTemplate) -> str:
    """
    Rewrites a query using the provided ChatOpenAI language model and memory.

    Parameters:
        llm (ChatOpenAI): The ChatOpenAI language model instance to use for rewriting.
        memory (str): The memory or context to incorporate into the query rewriting process.
        query_rewriter_template (str): The query rewriting template used for invoking the language model.

    Returns:
        str: The rewritten query generated by the language model.

    Example:
        >>> query_rewiriter(llm_instance, "previous conversation")
        "Could you provide more details about the previous conversation?"
    """
    return llm.invoke(query_rewriter_template.format(memory=memory)).content

def hallucination_checker(llm: ChatOpenAI, sources: str, chat_history: str, hallucination_template: PromptTemplate) -> str:
    """
    Checks for hallucinations in generated text using the provided ChatOpenAI language model.

    Parameters:
        llm (ChatOpenAI): The ChatOpenAI language model instance to use for hallucination checking.
        sources (str): The sources or prompts used for generating the text to be checked.
        chat_history (str): The chat history or context in which the generated text was produced.
        hallucination_template (str): The hallucination checking template used for invoking the language model.

    Returns:
        str: The result of hallucination checking provided by the language model. ("0"-No Hallucination or "1"-Possible Hallucination)

    Example:
        >>> hallucination_checker(llm_instance, "previous conversation", "How are you?", template=hallucination_template)
        "0"
    """
    return llm.invoke(hallucination_template.format(sources=sources,chat_history=chat_history)).content

def get_relevant_docs(vector_store: MongoDBAtlasVectorSearch, query: str, about_org: str) -> dict:
    """
    Retrieves relevant documents from a MongoDBAtlasVectorSearch based on a query and context constraints.

    Parameters:
        vector_store (MongoDBAtlasVectorSearch): The MongoDBAtlasVectorSearch instance to search for relevant documents.
        query (str): The query used to search for relevant documents.
        about_org (str): Details about the organization.

    Returns:
        dict: A dictionary containing the retrieved context and relevant document IDs.

    Example:
        >>> get_relevant_docs(vector_store_instance, "breakfast cereals")
        {'context': '\nSource 1 : abc\nSource 2: def\nSource 3: ghi',
         'context_id': ['product-abc', 'product-def', 'product-ghi']}
    """
    context=f'\nSource 1: \n\n{about_org}\n\n'
    source_num,context_id = 2,[]
    docs = vector_store.similarity_search(query,k=3)
    try:
        for i in docs:
            if calculate_tokens(context+i.page_content) < 3500:
                context += '\nSource {}: \n\n{}\n'.format(source_num,i.page_content)
                source_num+=1
                context_id.append(i.metadata['id'])
    except Exception as e:
        logging.error(f"get_relevant_docs(): Couldn't retrieve content: {e}")

    return {'context':context,'context_id':context_id}

def class_query_handler(llm_chain: LLMChain, llm: ChatOpenAI,
                        chatlog_collection: Collection, 
                        vector_store: MongoDBAtlasVectorSearch, 
                        query_rewriter_template: PromptTemplate, 
                        hallucination_template: PromptTemplate,
                        about_org: str, model_name: str, query: str, 
                        hallucination_check: bool, sub_class: str, session_id: str, **kwargs) -> dict:
    """
    Handles classification queries using a pipeline of language models and relevant document retrieval.

    Parameters:
        llm_chain (LLMChain): The LLMChain instance representing the pipeline of language models.
        llm (ChatOpenAI): The ChatOpenAI language model instance.
        chatlog_collection (Collection): The MongoDB collection containing chat logs.
        vector_store (MongoDBAtlasVectorSearch): The MongoDBAtlasVectorSearch instance for vector similarity search.
        query_rewriter_template (PromptTemplate): The prompt template for query rewriter. 
        hallucination_template (PromptTemplate): The prompt template for hallucination checker.
        about_org (str): Details about the organization.
        model_name (str): The name of the model being used.
        query (str): The input query to be processed.
        hallucination_check (bool): A flag indicating whether hallucination checking should be performed.
        sub_class (str): The subclass of the query.
        session_id (str): The session ID associated with the query.
        **kwargs: Additional keyword arguments.

    Returns:
        dict: A dictionary containing the response to the query.

    Example:
        >>> class_query_handler(llm_chain_instance, llm_instance, chatlog_collection_instance, vector_store_instance, "model_name",
                                "How do I change my password?", True, "subclass", "session_123")
    """
    if sub_class!='greetings':
        try:
            kwargs['status'].update(label=':green[**Retrieving relevant items ..**]',state='running',expanded=False)            
        except:
            pass

        memory_list = list(reversed(list(chatlog_collection.find({"session_id": session_id, "class": "query"}, {"query": 1, "text": 1, "_id": 0}).sort([("timestamp", -1)]).limit(3))))
        memory = ''.join(f"Human: {item['query']}\nAI: {item['text']}\n\n" for item in memory_list).rstrip('\n')
        logging.info(f'memory: {memory}')

        rewritten_query = query_rewiriter(llm=llm,memory=memory+'Human: '+query,query_rewriter_template=query_rewriter_template)
        logging.info(f'originial-query: {query}')
        logging.info(f'rewritten-query: {rewritten_query}')

        relevant_docs = get_relevant_docs(vector_store=vector_store,query=rewritten_query,about_org=about_org)
        logging.info(f'relevant-docs: {relevant_docs["context_id"]}')

        try:
            kwargs['status'].update(label=':green[**Generating response ..**]',state='running',expanded=False)
        except:
            pass
        # request_length = calculate_tokens(relevant_docs['context']+memory+kwargs['query'])
    else:
        memory, rewritten_query = '',''
        relevant_docs = {}
        relevant_docs['context'] = ''
        relevant_docs['context_id'] = []

    try:
        chain_resp = llm_chain.invoke(input={'context':relevant_docs['context'],'chat_history':memory,'query':query})
    except Exception as e:
        chain_resp = {}
        chain_resp['text'] = str(e)
        chain_resp['query'] = query

    try:
        kwargs['status'].update(label=':green[**Publishing response ..**]',state='running',expanded=False)
    except:
        pass
    chain_resp['context_id'] = relevant_docs['context_id']
    chain_resp['chat_history'] = memory
    chain_resp['model_name'] = model_name
    chain_resp['search_query'] = rewritten_query

    if hallucination_check == True: 
        chain_resp['hallucination_flag'] = hallucination_checker(sources=relevant_docs['context'],
                                                                 chat_history=memory,llm=llm,
                                                                 hallucination_template=hallucination_template)
    else:
        chain_resp['hallucination_flag'] = 'Not Invoked'
    
    return chain_resp

def class_complaint_handler(sub_class: str) -> str:
    """
    Handles complaints and provides assistance accordingly.

    Parameters:
        sub_class (str): The subclass of the complaint.

    Returns:
        str: A message indicating assistance for handling the complaint.

    Example:
        >>> class_complaint_handler("billing")
    """
    return "Sure! I can help you with your case. Please fill your details in this form .."

def subclass_create_complaint_handler(salesforce_client: Salesforce, customer_name: str, 
                                      phone: str, email: str, subject: str, description: str, 
                                      priority: str = 'Low', origin: str = 'Chat') -> dict:
    """
    Create a new complaint case in Salesforce.

    Args:
        salesforce_client (Salesforce): An instance of the Salesforce client.
        customer_name (str): The name of the customer.
        phone (str): The phone number of the customer.
        email (str): The email address of the customer.
        subject (str): The subject of the complaint.
        description (str): The description of the complaint.
        priority (str, optional): The priority of the complaint (default is 'Low').
        origin (str, optional): The origin of the complaint (default is 'Chat').

    Returns:
        dict: A dictionary containing information about the result of the operation.
              If the operation was successful, the dictionary will contain a message
              indicating that the case has been created successfully. If the operation
              failed, the dictionary will contain an error message and the success flag
              will be set to False.

    Example:
        # Create a new complaint case
        result = subclass_create_complaint_handler(salesforce_client, 'John Doe', 
                                                    '+1234567890', 'john@example.com', 
                                                    'Product Quality Issue', 
                                                    'The product I received was damaged.',
                                                    priority='High')
    """
    resp = {}
    try: 
        resp = salesforce_client.Case.create({'SuppliedName':customer_name,'SuppliedPhone':phone, 
                                   'SuppliedEmail':email, 'Subject':subject, 'Description':description,
                                   'Priority':priority, 'Origin':origin})
        resp['message'] = 'Your case has been created successfully!'
    except Exception as e:
        logging.error(f'SUBCLASS_CREATE_COMPLAINT_HANDLER: {e}')
        resp['success'] = False
        resp['message'] = 'Unable to create your case. Please contact our Customer Support team'
    return resp

def subclass_update_complaint_handler(salesforce_client: Salesforce, case_number: str,
                                      customer_name: str = '', phone: str = '', email: str = '', 
                                      subject: str = '', description: str = '') -> dict:
    """
    Update a complaint case in Salesforce using case number.

    Args:
        salesforce_client (Salesforce): An instance of the Salesforce client.
        case_number (str): The case number of the complaint to be updated.
        customer_name (str, optional): The updated name of the customer (default is '').
        phone (str, optional): The updated phone number of the customer (default is '').
        email (str, optional): The updated email address of the customer (default is '').
        subject (str, optional): The updated subject of the complaint (default is '').
        description (str, optional): The updated description of the complaint (default is '').

    Returns:
        dict: A dictionary containing information about the result of the operation.
              If the operation was successful, the dictionary will contain a message
              indicating that the case has been updated successfully. If the operation
              failed, the dictionary will contain an error message.

    Example:
        # Update an existing complaint case
        result = subclass_update_complaint_handler(salesforce_client, '123456', 
                                                    customer_name='Jane Doe', 
                                                    phone='+1234567890', 
                                                    email='jane@example.com', 
                                                    subject='Resolved Issue', 
                                                    description='The issue has been resolved.')
    """
    update_case = {}
    resp = {}
    if case_number != '' and case_number!= None:
        try:
            case_id = salesforce_client.query("SELECT Id FROM case WHERE CaseNumber = '{}'".format(case_number))['records'][0]['Id']
        except Exception as e:
            logging.error(f'SUBCLASS_UPDATE_COMPLAINT_HANDLER 1: {e}')
            resp['message'] = 'Unable to update your case. Please contact our Customer Support team'
        if customer_name != '': 
            update_case['SuppliedName'] = customer_name
        if phone != '':
            update_case['Phone'] = phone
        if email != '':
            update_case['Email'] = email
        if subject != '':
            update_case['Subject'] = subject
        if description != '':
            update_case['Description'] = description
        try:
            status_code = salesforce_client.Case.update(case_id,update_case)
            if status_code == 204:
                resp['message'] = 'Your case has been updated successfully!'
        except Exception as e:
            logging.error(f'SUBCLASS_UPDATE_COMPLAINT_HANDLER 2: {e}')
            resp['message'] = 'Unable to update your case. Please contact our Customer Support team'
    else:
        resp['message'] = 'Unable to update your case due to Invalid Case Number. Please contact our Customer Support team'
    return resp

def subclass_view_complaint_handler(salesforce_client: Salesforce, phone: str = ''):
    """
    Retrieve complaint cases from Salesforce based on the provided phone number.

    Args:
        salesforce_client (Salesforce): An instance of the Salesforce client.
        phone (str, optional): The phone number of the customer (default is '').

    Returns:
        dict: A dictionary containing information about the retrieved cases.
              If cases are found, the dictionary will contain details of each case,
              including case number, subject, and status. If no cases are found,
              the dictionary will contain a message indicating that no cases were found.
              If an error occurs during retrieval, the dictionary will contain an error message.

    Example:
        # Retrieve complaint cases based on a phone number
        result = subclass_view_complaint_handler(salesforce_client, '1234567890')
    """
    query = f"SELECT CaseNumber, Subject, Status from case WHERE SuppliedPhone = '{phone}'"
    resp = {}
    message = 'Here are the Case details: \n\n\n\n---------------'
    try:
        resp = salesforce_client.query(query)
    except Exception as e:
        logging.error(f'SUBCLASS_VIEW_COMPLAINT_HANDLER: {e}')
        resp['totalSize'] = -1

    if resp['totalSize'] >= 1:
        for i in resp['records']:
            message += '\n\n\n**Case Number:** '+i['CaseNumber']+'\
                        \n\n\n**Subject:** '+i['Subject']+'\
                        \n\n\n**Case Status:** '+i['Status']+'\
                        \n\n\n---------------'
    
    elif resp['totalSize'] == -1:
        message = 'Unable to retrieve your case(s). Please contact our Customer Support team.'
    else:
        message = 'No case(s) found. Please contact our Customer Support team.'

    resp['message'] = message
    return resp

def class_tangential_handler(sub_class: str, company_name: str) -> str:
    """
    Handles tangential queries based on their subclass.

    Parameters:
        sub_class (str): The subclass of the tangential query.

    Returns:
        str: A response tailored to the subclass of the tangential query.

    Example:
        >>> class_tangential_handler("unrelated")
    """
    if sub_class == 'unrelated':
        return ("I'm sorry, It seems that your question may be a bit out of scope. "
                f"I'm tuned to answer questions related only to {company_name}"
                "Is there anything else I can help you with?")
    else:
        return ("I'm sorry, It seems that your question may be a bit unclear. "
                "Could you please provide more details or clarify your inquiry? "
                "This will help me better understand your needs and provide a more accurate and helpful response. ")

def class_order_handler(sub_class: str) -> str:
    """
    Handles order-related queries.

    Parameters:
        sub_class (str): The subclass of the order-related query.

    Returns:
        str: A message indicating inability to handle orders at the moment.

    Example:
        >>> class_order_handler("shipping")
    """
    return "Sorry! I'm not yet ready to help with orders."

def chat_response(query: str, llm_chain: LLMChain, llm: ChatOpenAI, 
                  chatlog_collection: Collection,
                  vector_store: MongoDBAtlasVectorSearch, 
                  classification_template: PromptTemplate, 
                  query_rewriter_template: PromptTemplate,
                  hallucination_template: PromptTemplate,
                  about_org: str, org_name: str,
                  hallucination_check:bool = False, log: bool = True, status = None, 
                  session_id: str = 'test-session', username: str = 'test-user',
                  model_name: str = os.getenv('GPT_3_MODEL')) -> dict:
    """
    Generates a response to a user query based on classification and processing through a pipeline of language models.

    Parameters:
        query (str): The user query to generate a response for.
        llm_chain (LLMChain): The LLMChain instance representing the pipeline of language models.
        llm (ChatOpenAI): The ChatOpenAI language model instance.
        chatlog_collection (Collection): The MongoDB collection containing chat logs.
        vector_store (MongoDBAtlasVectorSearch): The MongoDBAtlasVectorSearch instance for vector similarity search.
        query_rewriter_template (PromptTemplate): The prompt template for query rewriter. 
        hallucination_template (PromptTemplate): The prompt template for hallucination checker.
        org_name (str): Name of the organization.
        about_org (str): Details about the organization.
        hallucination_check (bool): A flag indicating whether hallucination checking should be performed. Default is False.
        log (bool): A flag indicating whether the chat log should be stored in the collection. Default is True.
        status: Optional. Status information for tracking progress.
        session_id (str): The session ID associated with the query. Default is 'test-session'.
        username (str): The username associated with the query. Default is 'test-user'.
        model_name (str): The name of the model being used. Default is os.getenv('GPT_3_MODEL').
        **kwargs: Additional keyword arguments.

    Returns:
        dict: A dictionary containing the response to the query.

    Example:
        >>> chat_response("How can I track my order?", llm_chain_instance, llm_instance, 
                          chatlog_collection_instance, vector_store_instance, hallucination_check=True,
                          log=True, session_id="session_123", username="user123")
    """
    start = time()

    with get_openai_callback() as cb:
        label_resp = classify_query(llm = llm, query=query, classification_template=classification_template)

        if len(label_resp) == 1:
            label_resp.append('unknown')
        
        if label_resp[0] == 'query' or label_resp[0] == '1':
            chain_resp = class_query_handler(llm=llm, llm_chain=llm_chain,
                                             chatlog_collection = chatlog_collection, 
                                             model_name = model_name,
                                             query = query, vector_store = vector_store,
                                             query_rewriter_template = query_rewriter_template,
                                             hallucination_template = hallucination_template,
                                             hallucination_check = hallucination_check, 
                                             about_org = about_org,
                                             status=status, sub_class = label_resp[1],
                                             session_id=session_id)
            
            chain_resp.update({'class':label_resp[0],'sub_class':label_resp[1]})
        
        elif label_resp[0] == 'complaint' or label_resp[0] == '2':
            chain_resp={'query':query,
                        'class':label_resp[0],
                        'sub_class':label_resp[1],
                        'text':class_complaint_handler(sub_class=label_resp[1]),
                        'context_id':[],
                        'search_query':'',
                        'hallucination_flag':'Not Invoked',
                        }
        
        elif label_resp[0] == 'order' or label_resp[0] == '3':
            chain_resp={'query':query,
                        'class':label_resp[0],
                        'sub_class':label_resp[1],
                        'text':class_order_handler(sub_class=label_resp[1]),
                        'context_id':[],
                        'search_query':'',
                        'hallucination_flag':'Not Invoked',
                        }
            
        else:
            chain_resp={'query':query,
                        'class':'tangential',
                        'sub_class':label_resp[1],
                        'text':class_tangential_handler(sub_class=label_resp[1],org_name=org_name),
                        'context_id':[],
                        'search_query':'',
                        'hallucination_flag':'Not Invoked',
                        }
            
    chain_resp.update({'total_time':round(time()-start,2),
                       'prompt_tokens':round(cb.prompt_tokens,3),
                       'completion_tokens':round(cb.completion_tokens,3),
                       'total_tokens': round(cb.total_tokens,3),
                       'total_cost': round(((cb.prompt_tokens/1000)*0.0005)+((cb.completion_tokens/1000)*0.0015),5),
                       'model_name': model_name,
                       'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                       'session_id': session_id,
                       'username': username,
                       })
    if log == True: 
        chatlog_collection.insert_one(chain_resp)
    return chain_resp

def hard_filter(query: str, keyword: list[str],
                substring: list[str],
                max_allowed_characters: int,
                max_allowed_numbers:int,
                max_allowed_special_characters:int) -> dict:
    """
    Filters a query string based on various criteria including presence of sensitive keywords,
    substrings, maximum allowed characters, numbers, and special characters.

    Args:
        query (str): The input query string to be filtered.
        keyword (list[str]): List of sensitive keywords. If any keyword is found in the query,
            the function will return a signal indicating it.
        substring (list[str]): List of substrings. If any substring is found in the query,
            the function will return a signal indicating it.
        max_allowed_characters (int): Maximum allowed characters in the query. If the query exceeds
            this limit, the function will return a signal indicating it.
        max_allowed_numbers (int): Maximum allowed numbers in the query. If the number of digits in
            the query exceeds this limit, the function will return a signal indicating it.
        max_allowed_special_characters (int): Maximum allowed special characters in the query.
            If the count of special characters exceeds this limit, the function will return a signal
            indicating it.

    Returns:
        dict: A dictionary containing a signal indicating whether the query passed the filtering
        conditions and a message describing the result.

    Example:
        >>> query = "This is a sensitive keyword query"
        >>> keyword = ["sensitive"]
        >>> substring = ["key"]
        >>> max_allowed_characters = 50
        >>> max_allowed_numbers = 2
        >>> max_allowed_special_characters = 3
        >>> hard_filter(query, keyword, substring, max_allowed_characters,
                        max_allowed_numbers, max_allowed_special_characters)
        {'signal': False, 'message': "Prompt contains 'sensitive' which is a sensitive keyword"}
    """
    query = query.lower()

    for word in keyword:
        pattern = r'\b{}\b'.format(re.escape(word.lower()))
        if re.search(pattern, query):
            return {'signal':False, 'message':"Prompt contains '"+word+"' which is a sensitive keyword"}
        
    for word in substring:
        if word.lower() in query:
            return {'signal':False, 'message':"Prompt contains '"+word+"' as a substring"}
    
    num_numbers = sum(char.isdigit() for char in query)
    num_special_chars = len(re.findall(r'[^a-zA-Z0-9\s]', query))

    if num_numbers >= max_allowed_numbers:
        return {'signal':False, 'message':"Max allowed numbers exceeded"}
    
    elif len(query) >= max_allowed_characters:
        return {'signal':False, 'message':"Max allowed characters exceeded"}
    
    elif num_special_chars >= max_allowed_special_characters:
        return {'signal':False, 'message':"Max allowed special characters"}
    
    else:
        return {'signal':True, 'message':'All conditions satisfied'}
        
def soft_filter(query: str, vector_store: MongoDBAtlasVectorSearch, top_k: int = 3, threshold: float = 0.75) -> dict:
    """
    Soft filters a query string based on similarity search using a MongoDBAtlasVectorSearch object.

    Args:
        query (str): The input query string to be filtered.
        vector_store (MongoDBAtlasVectorSearch): MongoDB Atlas Vector Search object used for similarity search.
        top_k (int, optional): Number of top similar documents to retrieve. Defaults to 3.
        threshold (float, optional): Sesnitivity measure to filter relevant documents.

    Returns:
        dict: A dictionary containing a signal indicating whether the query passed the filtering
        conditions and a message describing the result.

    Example:
        >>> query = "This is a sensitive keyword query"
        >>> vector_store = MongoDBAtlasVectorSearch()
        >>> soft_filter(query, vector_store)
        {'signal': True, 'message': 'All conditions satisfied'}
    """
    search_results = vector_store.similarity_search_with_score(query=query,k=top_k)
    logging.info(f'search-result: {search_results}')
    
    if not search_results or search_results[0][1] <= threshold:
        return {'signal':True, 'message':'All conditions satisfied'}
    else:
        return {'signal':False, 'message':f'Soft filter failed. Input sensitive and similar to "{search_results[0][0].page_content}" by {round(search_results[0][1]*100)}%'}
    
def get_external_search_results(query: str, llm: ChatOpenAI,
                                vector_store: MongoDBAtlasVectorSearch,
                                max_numbers: int = 100,
                                max_characters: int = 10_000,
                                max_special_characters: int = 100,
                                keyword: str = '',
                                substring: str = '',
                                **kwargs) -> dict:
    """
    Retrieves external search results after performing hard and soft filtering on the query.

    Args:
        query (str): The input query string to search.
        llm (ChatOpenAI): An instance of the ChatOpenAI class for generating responses.
        vector_store (MongoDBAtlasVectorSearch): MongoDB Atlas Vector Search object used for similarity search.
        max_numbers (int, optional): Maximum allowed numbers in the query. Defaults to 100.
        max_characters (int, optional): Maximum allowed characters in the query. Defaults to 10,000.
        max_special_characters (int, optional): Maximum allowed special characters in the query. Defaults to 100.
        keyword (str, optional): List of sensitive keywords seperated by comma. Defaults to ''.
        substring (str, optional): List of substrings seperated by comma. Defaults to ''.
        **kwargs: Additional keyword arguments.

    Returns:
        dict: A dictionary containing the response and type.

    Example:
        >>> query = "This is a sensitive keyword query"
        >>> llm = ChatOpenAI()
        >>> vector_store = MongoDBAtlasVectorSearch()
        >>> get_external_search_results(query, llm, vector_store)
        {'response': '...', 'type': 'ES'}
    """
    try:
        kwargs['status'].update(label=':green[**Checking Filter**]',state='running',expanded=False)
    except:
        pass

    hard_filter_result = hard_filter(query=query,keyword=[word for word in keyword.split(',') if word.strip()],
                                     substring=[word for word in substring.split(',') if word.strip()],
                                    max_allowed_characters=int(max_characters),
                                    max_allowed_numbers=int(max_numbers),
                                    max_allowed_special_characters=int(max_special_characters))
    
    if hard_filter_result['signal'] == False:
        return {
                'response':'Error: '+hard_filter_result['message'],
                'type': 'ES'
            }
    
    soft_filter_result = soft_filter(query=query,vector_store=vector_store)
    logging.info(f'soft-filter-result: {soft_filter_result}')      

    if soft_filter_result['signal'] == False:
        return {
                'response':'Error: '+soft_filter_result['message'],
                'type': 'ES'
            }
    try:
        kwargs['status'].update(label=':green[**Generating Response**]',state='running',expanded=False)
    except:
        pass

    return {
            'response':llm.invoke(query).content,
            'type': 'ES'
        }
    
def get_internal_search_results(query: str, llm: ChatOpenAI, vector_store: MongoDBAtlasVectorSearch, 
                                top_k: int = 3, **kwargs) -> dict:
    """
    Retrieves internal search results and generates a response for given query.

    Args:
        query (str): The input query string to search.
        llm (ChatOpenAI): An instance of the ChatOpenAI class for generating responses.
        vector_store (MongoDBAtlasVectorSearch): MongoDB Atlas Vector Search object used for similarity search.
        top_k (int, optional): Number of top relevant documents to retrieve. Defaults to 3.
        **kwargs: Additional keyword arguments.

    Returns:
        dict: A dictionary containing the response, type, and context ID.

    Example:
        >>> query = "This is a sensitive keyword query"
        >>> llm = ChatOpenAI()
        >>> vector_store = MongoDBAtlasVectorSearch()
        >>> get_internal_search_results(query, llm, vector_store)
        {'response': '...', 'type': 'IS', 'context_id': [...] }
    """
    try:
        kwargs['status'].update(label=':green[**Retrieving Relevant Documents**]',state='running',expanded=False)
    except:
        pass

    relevant_docs = vector_store.similarity_search(query=query,top_k=top_k)
    relevant_content = ''
    context_id = []
    source = 1
    for i in relevant_docs:
        relevant_content+= f'\nSource {source}:\n\n'
        source+=1
        relevant_content += i.page_content
        relevant_content+= '\n\n'
        context_id.append(i.metadata['filename'])

    try:
        kwargs['status'].update(label=':green[**Generating Response**]',state='running',expanded=False)
    except:
        pass

    return {
            'response':llm.invoke(f"You're given peices of internal document to answer. Please use the documents to answer the user question, If you don't know the answer just say I don't know. \nDocuments:\n{relevant_content}\n\nQuestion: {query}\nAnswer: ").content,
            'type': 'IS',
            'context_id':context_id
        }